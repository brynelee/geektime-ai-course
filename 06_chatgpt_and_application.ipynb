{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT来了，更快的速度更低的价格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "class Conversation:\n",
    "    def __init__(self, prompt, num_of_round):\n",
    "        self.prompt = prompt\n",
    "        self.num_of_round = num_of_round\n",
    "        self.messages = []\n",
    "        self.messages.append({\"role\": \"system\", \"content\": self.prompt})\n",
    "\n",
    "    def ask(self, question):\n",
    "        try:\n",
    "            self.messages.append( {\"role\": \"user\", \"content\": question})\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=self.messages,\n",
    "                temperature=0.5,\n",
    "                max_tokens=2048,\n",
    "                top_p=1,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return e\n",
    "\n",
    "        message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": message})\n",
    "        \n",
    "        if len(self.messages) > self.num_of_round*2 + 1:\n",
    "            del self.messages[1:3]\n",
    "        return message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User : 你是谁？\n",
      "Assistant : 我是一个AI语言模型，可以用中文回答各种问题，包括做菜的问题。\n",
      "\n",
      "User : 请问鱼香肉丝怎么做？\n",
      "Assistant : 鱼香肉丝的做法：\n",
      "1. 猪里脊肉切成细丝，用料酒、盐、生抽腌制10分钟。\n",
      "2. 香葱、姜、蒜切末，泡辣椒切段备用。\n",
      "3. 锅里放油，将腌制好的猪肉丝煸炒至变色，盛出备用。\n",
      "4. 锅中留底油，加入泡辣椒段、葱姜蒜末煸炒出香味，加入豆瓣酱、甜面酱、醋、糖、盐、鸡精、清水调成酱汁。\n",
      "5. 将煸炒好的猪肉丝倒入酱汁中，翻炒均匀，最后加入青红椒丝翻炒即可。\n",
      "\n",
      "User : 那蚝油牛肉呢？\n",
      "Assistant : 蚝油牛肉的做法：\n",
      "1. 将牛肉切成薄片，用料酒、盐、生粉腌制10分钟。\n",
      "2. 青红椒切丝，葱姜切末备用。\n",
      "3. 锅中倒油，将腌制好的牛肉片煸炒至变色，盛出备用。\n",
      "4. 锅中留底油，加入葱姜末煸炒出香味，加入青红椒丝煸炒。\n",
      "5. 加入蚝油、盐、糖、鸡精、清水调成酱汁，煮沸后加入煸炒好的牛肉片，翻炒均匀。\n",
      "6. 最后加入少量水淀粉勾芡，翻炒均匀即可。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
    "1. 你的回答必须是中文\n",
    "2. 回答限制在100个字以内\"\"\"\n",
    "conv1 = Conversation(prompt, 3)\n",
    "question1 = \"你是谁？\"\n",
    "print(\"User : %s\" % question1)\n",
    "print(\"Assistant : %s\\n\" % conv1.ask(question1))\n",
    "\n",
    "question2 = \"请问鱼香肉丝怎么做？\"\n",
    "print(\"User : %s\" % question2)\n",
    "print(\"Assistant : %s\\n\" % conv1.ask(question2))\n",
    "\n",
    "question3 = \"那蚝油牛肉呢？\"\n",
    "print(\"User : %s\" % question3)\n",
    "print(\"Assistant : %s\\n\" % conv1.ask(question3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User : 我问你的第一个问题是什么？\n",
      "Assistant : 你的第一个问题是“你是谁？”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question4 = \"我问你的第一个问题是什么？\"\n",
    "print(\"User : %s\" % question4)\n",
    "print(\"Assistant : %s\\n\" % conv1.ask(question4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User : 我问你的第一个问题是什么？\n",
      "Assistant : 你的第一个问题是“请问鱼香肉丝怎么做？”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question5 = \"我问你的第一个问题是什么？\"\n",
    "print(\"User : %s\" % question5)\n",
    "print(\"Assistant : %s\\n\" % conv1.ask(question5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过API计算Token数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conversation2:\n",
    "    def __init__(self, prompt, num_of_round):\n",
    "        self.prompt = prompt\n",
    "        self.num_of_round = num_of_round\n",
    "        self.messages = []\n",
    "        self.messages.append({\"role\": \"system\", \"content\": self.prompt})\n",
    "\n",
    "    def ask(self, question):\n",
    "        try:\n",
    "            self.messages.append( {\"role\": \"user\", \"content\": question})\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=self.messages,\n",
    "                temperature=0.5,\n",
    "                max_tokens=2048,\n",
    "                top_p=1,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return e\n",
    "\n",
    "        message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        num_of_tokens = response['usage']['total_tokens']\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": message})\n",
    "        \n",
    "        if len(self.messages) > self.num_of_round*2 + 1:\n",
    "            del self.messages[1:3]\n",
    "        return message, num_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "询问 {你是谁？} 消耗的token数量是 : 121\n",
      "询问 {请问鱼香肉丝怎么做？} 消耗的token数量是 : 419\n",
      "询问 {那蚝油牛肉呢？} 消耗的token数量是 : 731\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-QJFEqyGGulP668cGrGtNfsUU on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable RateLimitError object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e38658374a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mquestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mquestion1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0manswer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"询问 {%s} 消耗的token数量是 : %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable RateLimitError object"
     ]
    }
   ],
   "source": [
    "conv2 = Conversation2(prompt, 3)\n",
    "questions = [question1, question2, question3, question4, question5]\n",
    "for question in questions:\n",
    "    answer, num_of_tokens = conv2.ask(question)\n",
    "    print(\"询问 {%s} 消耗的token数量是 : %d\" % (question, num_of_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过Tiktoken库计算Token数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总共消耗的token数量是 : 107\n",
      "Prompt消耗 65 Token, 问题消耗 5 Token，回答消耗 24 Token，总共消耗 94 Token\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "conv2 = Conversation2(prompt, 3)\n",
    "question1 = \"你是谁？\"\n",
    "answer1, num_of_tokens = conv2.ask(question1)\n",
    "print(\"总共消耗的token数量是 : %d\" % (num_of_tokens))\n",
    "\n",
    "prompt_count = len(encoding.encode(prompt))\n",
    "question1_count = len(encoding.encode(question1))\n",
    "answer1_count = len(encoding.encode(answer1))\n",
    "total_count = prompt_count + question1_count + answer1_count\n",
    "print(\"Prompt消耗 %d Token, 问题消耗 %d Token，回答消耗 %d Token，总共消耗 %d Token\" % (prompt_count, question1_count, answer1_count, total_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 91, 318, 5011, 91, 29, 9125, 198]\n",
      "[27, 91, 318, 6345, 91, 397]\n",
      "[27, 91, 318, 5011, 91, 29, 882, 198]\n",
      "[27, 91, 318, 5011, 91, 29, 78191, 198]\n",
      "系统拼接的标记消耗 36 Token\n"
     ]
    }
   ],
   "source": [
    "system_start_count = len(encoding.encode(\"<|im_start|>system\\n\"))\n",
    "print(encoding.encode(\"<|im_start|>system\\n\"))\n",
    "end_count = len(encoding.encode(\"<|im_end|>\\n\"))\n",
    "print(encoding.encode(\"<|im_end|>\\n\"))\n",
    "user_start_count = len(encoding.encode(\"<|im_start|>user\\n\"))\n",
    "print(encoding.encode(\"<|im_start|>user\\n\"))\n",
    "assistant_start_count = len(encoding.encode(\"<|im_start|>assistant\\n\"))\n",
    "print(encoding.encode(\"<|im_start|>assistant\\n\"))\n",
    "\n",
    "total_mark_count = system_start_count + user_start_count + assistant_start_count + end_count*2\n",
    "print(\"系统拼接的标记消耗 %d Token\" % total_mark_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio帮你快速搭建一个聊天界面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/xiaodong/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - gradio\n",
      "\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2022.12.~ --> anaconda/pkgs/main::ca-certificates-2023.01.10-hecd8cb5_0 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            conda-forge/noarch::certifi-2022.12.7~ --> anaconda/pkgs/main/osx-64::certifi-2022.12.7-py38hecd8cb5_0 \n",
      "  openssl            conda-forge::openssl-1.1.1t-hfd90126_0 --> anaconda/pkgs/main::openssl-1.1.1t-hca72f7f_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "prompt = \"\"\"你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
    "1. 你的回答必须是中文\n",
    "2. 回答限制在100个字以内\"\"\"\n",
    "\n",
    "conv = Conversation(prompt, 5)\n",
    "\n",
    "def predict(input, history=[]):\n",
    "    history.append(input)\n",
    "    response = conv.ask(input)\n",
    "    history.append(response)\n",
    "    responses = [(u,b) for u,b in zip(history[::2], history[1::2])]\n",
    "    return responses, history\n",
    "\n",
    "with gr.Blocks(css=\"#chatbot{height:350px} .overflow-y-auto{height:500px}\") as demo:\n",
    "    chatbot = gr.Chatbot(elem_id=\"chatbot\")\n",
    "    state = gr.State([])\n",
    "\n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter\").style(container=False)\n",
    "\n",
    "    txt.submit(predict, [txt, state], [chatbot, state])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "8114e84f04cf14e493992e1b725447accf84073d5ec18e7063d492738bf032cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
