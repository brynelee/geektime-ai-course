{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多次调用完成中译英，英文文答，英译中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please as an expert in machine learning, explain the principle of CNN.\n",
      "\n",
      "\n",
      "Convolutional Neural Networks (CNNs) are a type of artificial neural network used for image recognition, image classification, and object detection. They are used to analyze visual imagery and are considered to be one of the most powerful techniques for deep learning. \n",
      "\n",
      "A CNN works by taking an input image, applying a series of convolutional filters, and then pooling the results to create a feature map. This feature map is then used to identify patterns in the image. The convolutional filters are used to detect edges, curves, and other features in the image. The pooling layers are used to reduce the size of the feature map and to increase the accuracy of the model. The output of the CNN is then used to classify the image into one of the predefined classes.\n",
      "\n",
      "\n",
      "卷积神经网络（CNN）是一种用于图像识别、图像分类和物体检测的人工神经网络。它们用于分析视觉图像，被认为是深度学习最强大的技术之一。\n",
      "\n",
      "CNN通过输入图像、应用一系列卷积滤波器，然后池化结果来创建特征图，来完成工作。该特征图然后用于识别图像中的模式。卷积滤波器用于检测图像中的边缘、曲线和其他特征。池化层用于减小特征图的大小，并提高模型的准确性。CNN的输出然后用于将图像分类到预定义的类别中。\n"
     ]
    }
   ],
   "source": [
    "import openai, os\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", max_tokens=2048, temperature=0.5)\n",
    "\n",
    "en_to_zh_prompt = PromptTemplate(\n",
    "    template=\"请把下面这句话翻译成英文： \\n\\n {question}?\", input_variables=[\"question\"]\n",
    ")\n",
    "\n",
    "question_prompt = PromptTemplate(\n",
    "    template = \"{english_question}\", input_variables=[\"english_question\"]\n",
    ")\n",
    "\n",
    "zh_to_cn_prompt = PromptTemplate(\n",
    "    input_variables=[\"english_answer\"],\n",
    "    template=\"请把下面这一段翻译成中文： \\n\\n{english_answer}?\",\n",
    ")\n",
    "\n",
    "\n",
    "question_translate_chain = LLMChain(llm=llm, prompt=en_to_zh_prompt, output_key=\"english_question\")\n",
    "english = question_translate_chain.run(question=\"请你作为一个机器学习的专家，介绍一下CNN的原理。\")\n",
    "print(english)\n",
    "\n",
    "qa_chain = LLMChain(llm=llm, prompt=question_prompt, output_key=\"english_answer\")\n",
    "english_answer = qa_chain.run(english_question=english)\n",
    "print(english_answer)\n",
    "\n",
    "answer_translate_chain = LLMChain(llm=llm, prompt=zh_to_cn_prompt)\n",
    "answer = answer_translate_chain.run(english_answer=english_answer)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Langchain简化实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "Please, as an expert in machine learning, explain the principle of CNN.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "Convolutional Neural Networks (CNNs) are a type of deep learning neural network used for image recognition and classification. They are based on the idea of applying a filter to an image to extract features from it. This filter is applied to the image in a sliding window fashion and the output of the filter is used as an input to the next layer of the network. This process is repeated until a desired output is achieved. CNNs are used for tasks such as object detection, image segmentation, and image classification. The main advantage of CNNs is that they are able to learn features from the data without requiring any prior knowledge or manual feature engineering.\u001b[0m\n",
      "\u001b[38;5;200m\u001b[1;3m\n",
      "\n",
      "卷积神经网络（CNN）是一种深度学习神经网络，用于图像识别和分类。它们基于将滤镜应用于图像以从中提取特征的想法。这个滤镜以滑动窗口的方式应用于图像，滤镜的输出用作网络的下一层的输入。重复这个过程，直到达到预期的输出。CNN用于诸如物体检测、图像分割和图像分类等任务。CNN的主要优势在于，它们能够从数据中学习特征，而无需任何先验知识或手动特征工程。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "卷积神经网络（CNN）是一种深度学习神经网络，用于图像识别和分类。它们基于将滤镜应用于图像以从中提取特征的想法。这个滤镜以滑动窗口的方式应用于图像，滤镜的输出用作网络的下一层的输入。重复这个过程，直到达到预期的输出。CNN用于诸如物体检测、图像分割和图像分类等任务。CNN的主要优势在于，它们能够从数据中学习特征，而无需任何先验知识或手动特征工程。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chinese_qa_chain = SimpleSequentialChain(\n",
    "    chains=[question_translate_chain, qa_chain, answer_translate_chain], input_key=\"question\",\n",
    "    verbose=True)\n",
    "answer = chinese_qa_chain.run(question=\"请你作为一个机器学习的专家，介绍一下CNN的原理。\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多步骤引入不同输入参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "拜仁慕尼黑更胜一筹，获得欧冠冠军次数为5次，而其他球队的次数均不超过4次。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "q1_prompt = PromptTemplate(\n",
    "    input_variables=[\"year1\"],\n",
    "    template=\"{year1}年的欧冠联赛的冠军是哪支球队，只说球队名称。\"\n",
    ")\n",
    "q2_prompt = PromptTemplate(\n",
    "    input_variables=[\"year2\"],\n",
    "    template=\"{year2}年的欧冠联赛的冠军是哪支球队，只说球队名称。\"\n",
    ")\n",
    "q3_prompt = PromptTemplate(\n",
    "    input_variables=[\"team1\", \"team2\"],\n",
    "    template=\"{team1}和{team2}哪只球队获得欧冠的次数多一些？\"\n",
    ")\n",
    "chain1 = LLMChain(llm=llm, prompt=q1_prompt, output_key=\"team1\")\n",
    "chain2 = LLMChain(llm=llm, prompt=q2_prompt, output_key=\"team2\")\n",
    "chain3 = LLMChain(llm=llm, prompt=q3_prompt)\n",
    "\n",
    "sequential_chain = SequentialChain(chains=[chain1, chain2, chain3], input_variables=[\"year1\", \"year2\"], verbose=True)\n",
    "answer = sequential_chain.run(year1=2000, year2=2010)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过Langchain来完成自动撰写单元测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! stop is not default parameter.\n",
      "                    stop was transfered to model_kwargs.\n",
      "                    Please confirm that stop is what you intended.\n",
      "WARNING! stop is not default parameter.\n",
      "                    stop was transfered to model_kwargs.\n",
      "                    Please confirm that stop is what you intended.\n",
      "WARNING! stop is not default parameter.\n",
      "                    stop was transfered to model_kwargs.\n",
      "                    Please confirm that stop is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "def format_time(seconds):\n",
      "    minutes, seconds = divmod(seconds, 60)\n",
      "    hours, minutes = divmod(minutes, 60)\n",
      "    if hours > 0:\n",
      "        return f\"{hours}h{minutes}min{seconds}s\"\n",
      "    elif minutes > 0:\n",
      "        return f\"{minutes}min{seconds}s\"\n",
      "    else:\n",
      "        return f\"{seconds}s\"\n",
      "#Below, each test case is represented by a tuple passed to the @pytest.mark.parametrize decorator.\n",
      "#The first element of the tuple is the name of the test case, and the second element is a list of tuples.\n",
      "#Each tuple in the list contains the input to the function and the expected output.\n",
      "@pytest.mark.parametrize(\"test_case, (input, expected)\", [\n",
      "    # Test positive integers\n",
      "    (\"1 second\", [(1, \"1s\")]),\n",
      "    (\"60 seconds\", [(60, \"1min\")]),\n",
      "    (\"3600 seconds\", [(3600, \"1h\")]),\n",
      "    (\"86400 seconds\", [(86400, \"1d\")]),\n",
      "    # Test negative integers\n",
      "    (\"-1 second\", [(-1, \"-1s\")]),\n",
      "    (\"-60 seconds\", [(-60, \"-1min\")]),\n",
      "    (\"-3600 seconds\", [(-3600, \"-1h\")]),\n",
      "    (\"-86400 seconds\", [(-86400, \"-1d\")]),\n",
      "    # Test 0\n",
      "    (\"0 seconds\", [(0, \"0s\")]),\n",
      "    # Test positive floats\n",
      "    (\"1.5 seconds\", [(1.5, \"1.5s\")]),\n",
      "    (\"60.5 seconds\", [(60.5, \"1min\")]),\n",
      "    (\"3600.5 seconds\", [(3600.5, \"1h\")]),\n",
      "    (\"86400.5 seconds\", [(86400.5, \"1d\")]),\n",
      "    # Test negative floats\n",
      "    (\"-1.5 seconds\", [(-1.5, \"-1.5s\")]),\n",
      "    (\"-60.5 seconds\", [(-60.5, \"-1min\")]),\n",
      "    (\"-3600.5 seconds\", [(-3600.5, \"-1h\")]),\n",
      "    (\"-86400.5 seconds\", [(-86400.5, \"-1d\")]),\n",
      "    # Test strings\n",
      "    (\"1 second\", [(\"1\", \"1s\")]),\n",
      "    (\"60 seconds\", [(\"60\", \"1min\")]),\n",
      "    (\"3600 seconds\", [(\"3600\", \"1h\")]),\n",
      "    (\"86400 seconds\", [(\"86400\", \"1d\")]),\n",
      "    # Test empty string\n",
      "    (\"empty string\", [(\"\", \"0s\")]),\n",
      "    # Test None\n",
      "    (\"None\", [(None, \"0s\")]),\n",
      "    # Test list\n",
      "    (\"list\", [([1, 2, 3], \"0s\")]),\n",
      "    # Test tuple\n",
      "    (\"tuple\", [((\"a\", \"b\", \"c\"), \"0s\")]),\n",
      "    # Test dict\n",
      "    (\"dict\", [({\"a\": 1, \"b\": 2, \"c\": 3}, \"0s\")]),\n",
      "    # Test set\n",
      "    (\"set\", [(set([1, 2, 3]), \"0s\")]),\n",
      "    # Test large exponent\n",
      "    (\"large exponent\", [(1e12, \"316224h46min40s\")]),\n",
      "])\n",
      "def test_format_time(test_case, input, expected):\n",
      "    # We use the pytest.raises context manager to test for exceptions\n",
      "    with pytest.raises(ValueError):\n",
      "        # The actual call to the function being tested is inside the with block\n",
      "        actual = format_time(input)\n",
      "        # We use the pytest.approx helper function to compare floats\n",
      "        assert actual == pytest.approx(expected)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "\n",
    "def write_unit_test(function_to_test, unit_test_package = \"pytest\"):\n",
    "    # 解释源代码的步骤\n",
    "    explain_code = \"\"\"\"# How to write great unit tests with {unit_test_package}\n",
    "\n",
    "    In this advanced tutorial for experts, we'll use Python 3.10 and `{unit_test_package}` to write a suite of unit tests to verify the behavior of the following function.\n",
    "    ```python\n",
    "    {function_to_test}\n",
    "    ```\n",
    "\n",
    "    Before writing any unit tests, let's review what each element of the function is doing exactly and what the author's intentions may have been.\n",
    "    - First,\"\"\"\n",
    "\n",
    "    explain_code_template = PromptTemplate(\n",
    "        input_variables=[\"unit_test_package\", \"function_to_test\"],\n",
    "        template=explain_code\n",
    "    )\n",
    "    explain_code_llm = OpenAI(model_name=\"text-davinci-002\", temperature=0.4, max_tokens=1000, \n",
    "            top_p=1, stop=[\"\\n\\n\", \"\\n\\t\\n\", \"\\n    \\n\"])\n",
    "    explain_code_step = LLMChain(llm=explain_code_llm, prompt=explain_code_template, output_key=\"code_explaination\")\n",
    "\n",
    "\n",
    "    # 创建测试计划示例的步骤\n",
    "    test_plan = \"\"\"\n",
    "        \n",
    "    A good unit test suite should aim to:\n",
    "    - Test the function's behavior for a wide range of possible inputs\n",
    "    - Test edge cases that the author may not have foreseen\n",
    "    - Take advantage of the features of `{unit_test_package}` to make the tests easy to write and maintain\n",
    "    - Be easy to read and understand, with clean code and descriptive names\n",
    "    - Be deterministic, so that the tests always pass or fail in the same way\n",
    "\n",
    "    `{unit_test_package}` has many convenient features that make it easy to write and maintain unit tests. We'll use them to write unit tests for the function above.\n",
    "\n",
    "    For this particular function, we'll want our unit tests to handle the following diverse scenarios (and under each scenario, we include a few examples as sub-bullets):\n",
    "    -\"\"\"\n",
    "    test_plan_template = PromptTemplate(\n",
    "        input_variables=[\"unit_test_package\", \"function_to_test\", \"code_explaination\"],\n",
    "        template= explain_code + \"{code_explaination}\" + test_plan\n",
    "    )\n",
    "    test_plan_llm = OpenAI(model_name=\"text-davinci-002\", temperature=0.4, max_tokens=1000, \n",
    "            top_p=1, stop=[\"\\n\\n\", \"\\n\\t\\n\", \"\\n    \\n\"])\n",
    "    test_plan_step = LLMChain(llm=test_plan_llm, prompt=test_plan_template, output_key=\"test_plan\")\n",
    "\n",
    "    # 撰写测试代码的步骤\n",
    "    starter_comment = \"Below, each test case is represented by a tuple passed to the @pytest.mark.parametrize decorator\"\n",
    "    prompt_to_generate_the_unit_test = \"\"\"\n",
    "\n",
    "Before going into the individual tests, let's first look at the complete suite of unit tests as a cohesive whole. We've added helpful comments to explain what each line does.\n",
    "```python\n",
    "import {unit_test_package}  # used for our unit tests\n",
    "\n",
    "{function_to_test}\n",
    "\n",
    "#{starter_comment}\"\"\"\n",
    "\n",
    "    unit_test_template = PromptTemplate(\n",
    "        input_variables=[\"unit_test_package\", \"function_to_test\", \"code_explaination\", \"test_plan\", \"starter_comment\"],\n",
    "        template= explain_code + \"{code_explaination}\" + test_plan + \"{test_plan}\" + prompt_to_generate_the_unit_test\n",
    "    )\n",
    "    unit_test_llm = OpenAI(model_name=\"text-davinci-002\", temperature=0.4, max_tokens=1000, stop=\"```\")\n",
    "    unit_test_step = LLMChain(llm=unit_test_llm, prompt=unit_test_template, output_key=\"unit_test\")\n",
    "\n",
    "    sequential_chain = SequentialChain(chains=[explain_code_step, test_plan_step, unit_test_step], \n",
    "                                    input_variables=[\"unit_test_package\", \"function_to_test\", \"starter_comment\"], verbose=True)\n",
    "    answer = sequential_chain.run(unit_test_package=unit_test_package, function_to_test=function_to_test, starter_comment=starter_comment)\n",
    "    return f\"\"\"#{starter_comment}\"\"\" + answer\n",
    "\n",
    "\n",
    "code = \"\"\"\n",
    "def format_time(seconds):\n",
    "    minutes, seconds = divmod(seconds, 60)\n",
    "    hours, minutes = divmod(minutes, 60)\n",
    "    if hours > 0:\n",
    "        return f\"{hours}h{minutes}min{seconds}s\"\n",
    "    elif minutes > 0:\n",
    "        return f\"{minutes}min{seconds}s\"\n",
    "    else:\n",
    "        return f\"{seconds}s\"\n",
    "\"\"\"\n",
    "\n",
    "import ast\n",
    "\n",
    "def write_unit_test_automatically(code, retry=3):\n",
    "    unit_test_code = write_unit_test(code)\n",
    "    all_code = code + unit_test_code\n",
    "    tried = 0\n",
    "    while tried < retry:\n",
    "        try:\n",
    "            ast.parse(all_code)\n",
    "            return all_code\n",
    "        except SyntaxError as e:\n",
    "            print(f\"Syntax error in generated code: {e}\")\n",
    "            all_code = code + write_unit_test(code)\n",
    "            tried += 1\n",
    "\n",
    "print(write_unit_test_automatically(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
