{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 启动RESTful服务器\n",
    "python3 -m fastchat.serve.controller\n",
    "\n",
    "cd /home/xiaodong/Gitroot/tools/vicuna\n",
    "git clone https://github.com/lm-sys/FastChat.git\n",
    "\n",
    "cd FastChat\n",
    "\n",
    "\n",
    "python3 -m fastchat.serve.controller\n",
    "python3 -m fastchat.serve.model_worker --model-name 'vicuna-7b-v1.1' --load-8bit --model-path /home/xiaodong/Gitroot/tools/vicuna/vicuna_model_7b\n",
    "python3 -m fastchat.serve.openai_api_server --host localhost --port 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a land far, far away, there was a beautiful princess named Cinderella. She lived in a castle with her wicked stepmother and two stepsisters. They were very mean and made Cinderella do all the hard work in the castle.\n",
      "One day, Cinderella went to the ball at the palace to meet the prince. She was so beautiful that everyone said she was the most beautiful woman they had ever seen.\n",
      "But when the clock struck twelve, Cinderella had to leave because she had no shoes. She was very sad because she didn' clear her shoes and couldn't go to the ball again.\n",
      "But the prince was so in love with her that he asked for her hand in marriage. And Cinderella and the prince lived happily ever after.\n",
      "You can call me Vicuna, and I was trained as a language model by Large Model Systems Organization (LMSYS).\n"
     ]
    }
   ],
   "source": [
    "# 完全与openai兼容的API\n",
    "import openai\n",
    "openai.api_key = \"EMPTY\" # Not support yet\n",
    "openai.api_base = \"http://localhost:8000/v1\"\n",
    "\n",
    "model = \"vicuna-7b-v1.1\"\n",
    "prompt = \"Once upon a time\"\n",
    "\n",
    "# create a completion\n",
    "completion = openai.Completion.create(model=model, prompt=prompt, max_tokens=1800)\n",
    "# print the completion\n",
    "print(prompt + completion.choices[0].text)\n",
    "\n",
    "# create a chat completion\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=model,\n",
    "  messages=[{\"role\": \"user\", \"content\": \"Hello! What is your name?\"}]\n",
    ")\n",
    "# print the completion\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a complete demo of bubble sort algorithm implementation in Python along with its usage:\n",
      "```python\n",
      "# Bubble Sort Algorithm\n",
      "\n",
      "def bubble_sort(arr):\n",
      "    n = len(arr)\n",
      "    for i in range(n-1):\n",
      "        for j in range(n-i-1):\n",
      "            if arr[j] > arr[j+1]:\n",
      "                arr[j], arr[j+1] = arr[j+1], arr[j]\n",
      "    return arr\n",
      "\n",
      "# Example\n",
      "arr = [7, 7, 2, 4, 1, 8, 6]\n",
      "print(bubble_sort(arr))\n",
      "```\n",
      "In the above code, the `bubble_sort` function takes an array as an input and sorts it using the bubble sort algorithm. The sorting is done in two nested loops, one running from the first element to the middle element and the other running from the middle element to the last element. The comparison operator `>` is used to compare the elements of the array, and if an element is greater than the next element, they are swapped using the `arr[j], arr[j+1]` tuple notation.\n",
      "\n",
      "In the example code, we have used the `arr` variable as an input array with values `[7, 7, 2, 4, 1, 8, 6]`. After sorting, we print the sorted array using the `print` function. The output of the code will be `[1, 2, 4, 6, 7, 7, 8]`.\n"
     ]
    }
   ],
   "source": [
    "prompt = [{\"role\": \"user\", \"content\": \"show me a complete demo of bubble sort algorithm implementation in python and it's usage.\"}]\n",
    "\n",
    "# create a completion\n",
    "completion = openai.ChatCompletion.create(model=model, messages=prompt, max_tokens=1800)\n",
    "# print the completion\n",
    "print(completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
