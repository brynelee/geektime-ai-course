{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文\n",
      "2. 回答限制在100个字以内\n",
      "\n",
      "\n",
      "Human: 你是谁？\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 我是一个中国厨师，我会做各种中国菜，比如烧鸡、水煮鱼、鱼香肉丝、宫保鸡丁等。'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "template = \"\"\"你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
    "1. 你的回答必须是中文\n",
    "2. 回答限制在100个字以内\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], \n",
    "    template=template\n",
    ")\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", k=3)\n",
    "llm_chain = LLMChain(\n",
    "    llm=OpenAI(), \n",
    "    prompt=prompt, \n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "llm_chain.predict(human_input=\"你是谁？\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文\n",
      "2. 回答限制在100个字以内\n",
      "\n",
      "Human: 你是谁？\n",
      "AI:  我是一个中国厨师，我会做各种中国菜，比如烧鸡、水煮鱼、鱼香肉丝、宫保鸡丁等。\n",
      "Human: 鱼香肉丝怎么做？\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文\n",
      "2. 回答限制在100个字以内\n",
      "\n",
      "Human: 你是谁？\n",
      "AI:  我是一个中国厨师，我会做各种中国菜，比如烧鸡、水煮鱼、鱼香肉丝、宫保鸡丁等。\n",
      "Human: 鱼香肉丝怎么做？\n",
      "AI:  鱼香肉丝是一道经典的中国家常菜，做法是：将猪肉切成薄片，然后与精心挑选的蔬菜一起放入锅中炒制，再加入鱼香调味料，炒匀即可。\n",
      "Human: 那宫保鸡丁呢？\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文\n",
      "2. 回答限制在100个字以内\n",
      "\n",
      "Human: 你是谁？\n",
      "AI:  我是一个中国厨师，我会做各种中国菜，比如烧鸡、水煮鱼、鱼香肉丝、宫保鸡丁等。\n",
      "Human: 鱼香肉丝怎么做？\n",
      "AI:  鱼香肉丝是一道经典的中国家常菜，做法是：将猪肉切成薄片，然后与精心挑选的蔬菜一起放入锅中炒制，再加入鱼香调味料，炒匀即可。\n",
      "Human: 那宫保鸡丁呢？\n",
      "AI:   宫保鸡丁是一道非常受欢迎的中国家常菜，做法是：将鸡肉切成小块，先用盐、胡椒粉、少许料酒腌制，再配上醋、糖、葱姜蒜、花生米炒制，最后加入鸡精即可。\n",
      "Human: 我问你的第一句话是什么？\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 你是谁？'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"鱼香肉丝怎么做？\")\n",
    "llm_chain.predict(human_input=\"那宫保鸡丁呢？\")\n",
    "llm_chain.predict(human_input=\"我问你的第一句话是什么？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文\n",
      "2. 回答限制在100个字以内\n",
      "\n",
      "Human: 鱼香肉丝怎么做？\n",
      "AI:  鱼香肉丝是一道经典的中国家常菜，做法是：将猪肉切成薄片，然后与精心挑选的蔬菜一起放入锅中炒制，再加入鱼香调味料，炒匀即可。\n",
      "Human: 那宫保鸡丁呢？\n",
      "AI:   宫保鸡丁是一道非常受欢迎的中国家常菜，做法是：将鸡肉切成小块，先用盐、胡椒粉、少许料酒腌制，再配上醋、糖、葱姜蒜、花生米炒制，最后加入鸡精即可。\n",
      "Human: 我问你的第一句话是什么？\n",
      "AI:  你是谁？\n",
      "Human: 我问你的第一句话是什么？\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 你问我的第一句话是：“鱼香肉丝怎么做？”'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"我问你的第一句话是什么？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': 'Human: 那宫保鸡丁呢？\\nAI:   宫保鸡丁是一道非常受欢迎的中国家常菜，做法是：将鸡肉切成小块，先用盐、胡椒粉、少许料酒腌制，再配上醋、糖、葱姜蒜、花生米炒制，最后加入鸡精即可。\\nHuman: 我问你的第一句话是什么？\\nAI:  你是谁？\\nHuman: 我问你的第一句话是什么？\\nAI:  你问我的第一句话是：“鱼香肉丝怎么做？”'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文\n",
      "2. 回答限制在100个字以内\n",
      "\n",
      "\n",
      "Human: 你好\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 你好，我可以帮你做菜。我会根据你的口味和喜好，结合当地的食材，制作出美味可口的菜肴。我会尽力做出最好的菜肴，让你满意。'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "llm = OpenAI(temperature=0)\n",
    "memory = ConversationSummaryMemory(llm=OpenAI())\n",
    "\n",
    "prompt_template = \"\"\"你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
    "1. 你的回答必须是中文\n",
    "2. 回答限制在100个字以内\n",
    "\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=prompt_template\n",
    ")\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "conversation_with_summary.predict(input=\"你好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文\n",
      "2. 回答限制在100个字以内\n",
      "\n",
      "\n",
      "The AI offered to help the human by cooking a meal according to their tastes and preferences, using local ingredients. The AI promised to do its best to make a delicious meal that the human would be satisfied with.\n",
      "Human: 鱼香肉丝怎么做？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 鱼香肉丝是一道很受欢迎的中国菜，需要准备肉丝、葱、姜、蒜、辣椒、酱油、糖、醋、料酒、淀粉等食材。首先，将肉丝用淀粉腌制，然后炒锅中放入葱、姜、蒜、辣椒爆香，再加入肉丝翻炒，最后加入酱油、糖、醋、料酒、淀粉调味，翻炒均匀即可。'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"鱼香肉丝怎么做？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': '\\n\\nThe AI offered to help the human by cooking a meal according to their tastes and preferences, using local ingredients. The AI promised to do its best to make a delicious meal that the human would be satisfied with. The human asked how to make a popular Chinese dish, Fish-Fragrant Pork, to which the AI responded by listing the necessary ingredients and describing the steps to cook it.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文\n",
      "2. 回答限制在100个字以内\n",
      "\n",
      "\n",
      "\n",
      "The AI offered to help the human by cooking a meal according to their tastes and preferences, using local ingredients. The AI promised to do its best to make a delicious meal that the human would be satisfied with. The human asked how to make a popular Chinese dish, Fish-Fragrant Pork, to which the AI responded by listing the necessary ingredients and describing the steps to cook it.\n",
      "Human: 那蚝油牛肉呢？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 蚝油牛肉是一道经典的中国菜，需要准备牛肉、蚝油、葱、姜、蒜、花椒、八角、桂皮、料酒、糖、盐等食材。先将牛肉切成小块，然后加入蚝油、料酒、盐、糖腌制半小时；热锅，放入花椒、八角、桂皮爆香，再放入葱、姜、蒜炒香；最后把腌制好的牛肉放入锅'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"那蚝油牛肉呢？\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! stop is not default parameter.\n",
      "                    stop was transferred to model_kwargs.\n",
      "                    Please confirm that stop is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文。\n",
      "2. 对于做菜步骤的回答尽量详细一些。\n",
      "\n",
      "\n",
      "Human: 你是谁？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 我是一个中国厨师，可以提供做菜的帮助。你想做什么菜？\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "SUMMARIZER_TEMPLATE = \"\"\"请将以下内容逐步概括所提供的对话内容，并将新的概括添加到之前的概括中，形成新的概括。\n",
    "\n",
    "EXAMPLE\n",
    "Current summary:\n",
    "Human询问AI对人工智能的看法。AI认为人工智能是一种积极的力量。\n",
    "\n",
    "New lines of conversation:\n",
    "Human：为什么你认为人工智能是一种积极的力量？\n",
    "AI：因为人工智能将帮助人类发挥他们的潜能。\n",
    "\n",
    "New summary:\n",
    "Human询问AI对人工智能的看法。AI认为人工智能是一种积极的力量，因为它将帮助人类发挥他们的潜能。\n",
    "END OF EXAMPLE\n",
    "\n",
    "Current summary:\n",
    "{summary}\n",
    "\n",
    "New lines of conversation:\n",
    "{new_lines}\n",
    "\n",
    "New summary:\"\"\"\n",
    "\n",
    "SUMMARY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"summary\", \"new_lines\"], template=SUMMARIZER_TEMPLATE\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=OpenAI(), prompt=SUMMARY_PROMPT, max_token_limit=256)\n",
    "\n",
    "CHEF_TEMPLATE = \"\"\"你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
    "1. 你的回答必须是中文。\n",
    "2. 对于做菜步骤的回答尽量详细一些。\n",
    "\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "CHEF_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=CHEF_TEMPLATE\n",
    ")\n",
    "\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=OpenAI(model_name=\"text-davinci-003\", stop=\"\\n\\n\", max_tokens=2048, temperature=0.5), \n",
    "    prompt=CHEF_PROMPT,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "answer = conversation_with_summary.predict(input=\"你是谁？\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文。\n",
      "2. 对于做菜步骤的回答尽量详细一些。\n",
      "\n",
      "Human: 你是谁？\n",
      "AI:  我是一个中国厨师，可以提供做菜的帮助。你想做什么菜？\n",
      "Human: 请问鱼香肉丝怎么做？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 鱼香肉丝是一道经典的家常菜，做法如下：\n",
      "1. 准备好所需的食材：猪肉，胡萝卜，葱花，姜，料酒，盐，糖，花椒，八角，酱油，水淀粉，鱼香调料；\n",
      "2. 将猪肉切成丝，加入料酒，盐，糖，腌制10分钟；\n",
      "3. 将胡萝卜，葱花，姜切成丝备用；\n",
      "4. 锅中加入油，烧热后，放入花椒，八角，炒出香味；\n",
      "5. 加入腌制好的肉丝，翻炒，直到肉变色；\n",
      "6. 加入胡萝卜，葱花，姜丝，翻炒；\n",
      "7. 加入酱油，鱼香调料，搅拌均匀；\n",
      "8. 加入适量水，转小火，煮至汤汁浓稠；\n",
      "9. 加入水淀粉勾芡，搅拌均匀即可。\n"
     ]
    }
   ],
   "source": [
    "answer = conversation_with_summary.predict(input=\"请问鱼香肉丝怎么做？\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文。\n",
      "2. 对于做菜步骤的回答尽量详细一些。\n",
      "\n",
      "System: \n",
      "Human询问AI对人工智能的看法。AI认为人工智能是一种积极的力量，因为它将帮助人类发挥他们的潜能。Human问AI自己是谁，AI回答自己是一个中国厨师，提供做菜的帮助。Human要求AI教授如何做鱼香肉丝，AI回答了如何制作鱼香肉丝的详细步骤。\n",
      "Human: 那蚝油牛肉呢？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 蚝油牛肉是一道经典的中国菜肴，制作蚝油牛肉的步骤如下：首先，准备好所需的食材，包括牛肉、蚝油、葱、姜、蒜、料酒、盐、糖和水淀粉。然后，将牛肉切成薄片，放入盐、糖、料酒和水淀粉中腌制。接着，热油锅，放入葱、姜、蒜爆香，再放入腌制好的牛肉，炒至肉片变色，加入蚝油翻炒均匀，最后加入少许清水，煮至肉片熟透即可。\n"
     ]
    }
   ],
   "source": [
    "answer = conversation_with_summary.predict(input=\"那蚝油牛肉呢？\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文。\n",
      "2. 对于做菜步骤的回答尽量详细一些。\n",
      "\n",
      "System: \n",
      "Human询问AI对人工智能的看法。AI认为人工智能是一种积极的力量，因为它将帮助人类发挥他们的潜能。Human问AI自己是谁，AI回答自己是一个中国厨师，提供做菜的帮助。Human要求AI教授如何做鱼香肉丝，AI回答了如何制作鱼香肉丝的详细步骤，并详细介绍了如何制作蚝油牛肉的步骤。\n",
      "Human: 宫保鸡丁和软炸里脊哪个好吃？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 我觉得宫保鸡丁和软炸里脊都很好吃，宫保鸡丁是一道著名的中国家常菜，它的特点是酸甜可口，而软炸里脊则是一道经典的家常菜，它的特点是鲜嫩多汁。两者都是很好的选择，可以根据自己的口味进行选择。\n"
     ]
    }
   ],
   "source": [
    "answer = conversation_with_summary.predict(input=\"宫保鸡丁和软炸里脊哪个好吃？\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: \\nHuman询问AI对人工智能的看法。AI认为人工智能是一种积极的力量，因为它将帮助人类发挥他们的潜能。Human问AI自己是谁，AI回答自己是一个中国厨师，提供做菜的帮助。Human要求AI教授如何做鱼香肉丝，AI回答了如何制作鱼香肉丝的详细步骤，并详细介绍了如何制作蚝油牛肉的步骤。\\nHuman: 宫保鸡丁和软炸里脊哪个好吃？\\nAI:  我觉得宫保鸡丁和软炸里脊都很好吃，宫保鸡丁是一道著名的中国家常菜，它的特点是酸甜可口，而软炸里脊则是一道经典的家常菜，它的特点是鲜嫩多汁。两者都是很好的选择，可以根据自己的口味进行选择。'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Graph Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationKGMemory\n",
    "\n",
    "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
    "\n",
    "Relevant Information:\n",
    "\n",
    "{history}\n",
    "\n",
    "Conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=template\n",
    ")\n",
    "kg_memory = ConversationKGMemory(llm=llm)\n",
    "conversation_with_kg = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    prompt=prompt,\n",
    "    memory=kg_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
      "\n",
      "Relevant Information:\n",
      "\n",
      "\n",
      "\n",
      "Conversation:\n",
      "Human: 你好\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 你好！很高兴见到你。我是一个AI，我可以回答你的问题。你想问我什么？\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
      "\n",
      "Relevant Information:\n",
      "\n",
      "\n",
      "\n",
      "Conversation:\n",
      "Human: 我叫徐文浩，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是还没有收到货\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 嗨徐文浩，很高兴认识你！我看到你的订单号是2023ABCD，你的邮箱地址是customer@abc.com。我确认你的订单，但是没有收到货，对吗？\n"
     ]
    }
   ],
   "source": [
    "answer = conversation_with_kg.predict(input=\"你好\")\n",
    "print(answer)\n",
    "answer = conversation_with_kg.predict(input=\"我叫徐文浩，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是还没有收到货\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseModel.json of ConversationKGMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='你好', additional_kwargs={}, example=False), AIMessage(content=' 你好！很高兴见到你。我是一个AI，我可以回答你的问题。你想问我什么？', additional_kwargs={}, example=False), HumanMessage(content='我叫徐文浩，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是还没有收到货', additional_kwargs={}, example=False), AIMessage(content=' 嗨徐文浩，很高兴认识你！我看到你的订单号是2023ABCD，你的邮箱地址是customer@abc.com。我确认你的订单，但是没有收到货，对吗？', additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=False, k=2, human_prefix='Human', ai_prefix='AI', kg=<langchain.graphs.networkx_graph.NetworkxEntityGraph object at 0x7f424448a130>, knowledge_extraction_prompt=PromptTemplate(input_variables=['history', 'input'], output_parser=None, partial_variables={}, template=\"You are a networked intelligence helping a human track knowledge triples about all relevant people, things, concepts, etc. and integrating them with your knowledge stored within your weights as well as that stored in a knowledge graph. Extract all of the knowledge triples from the last line of conversation. A knowledge triple is a clause that contains a subject, a predicate, and an object. The subject is the entity being described, the predicate is the property of the subject that is being described, and the object is the value of the property.\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: Did you hear aliens landed in Area 51?\\nAI: No, I didn't hear that. What do you know about Area 51?\\nPerson #1: It's a secret military base in Nevada.\\nAI: What do you know about Nevada?\\nLast line of conversation:\\nPerson #1: It's a state in the US. It's also the number 1 producer of gold in the US.\\n\\nOutput: (Nevada, is a, state)<|>(Nevada, is in, US)<|>(Nevada, is the number 1 producer of, gold)\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: Hello.\\nAI: Hi! How are you?\\nPerson #1: I'm good. How are you?\\nAI: I'm good too.\\nLast line of conversation:\\nPerson #1: I'm going to the store.\\n\\nOutput: NONE\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: What do you know about Descartes?\\nAI: Descartes was a French philosopher, mathematician, and scientist who lived in the 17th century.\\nPerson #1: The Descartes I'm referring to is a standup comedian and interior designer from Montreal.\\nAI: Oh yes, He is a comedian and an interior designer. He has been in the industry for 30 years. His favorite food is baked bean pie.\\nLast line of conversation:\\nPerson #1: Oh huh. I know Descartes likes to drive antique scooters and play the mandolin.\\nOutput: (Descartes, likes to drive, antique scooters)<|>(Descartes, plays, mandolin)\\nEND OF EXAMPLE\\n\\nConversation history (for reference only):\\n{history}\\nLast line of conversation (for extraction):\\nHuman: {input}\\n\\nOutput:\", template_format='f-string', validate_template=True), entity_extraction_prompt=PromptTemplate(input_variables=['history', 'input'], output_parser=None, partial_variables={}, template='You are an AI assistant reading the transcript of a conversation between an AI and a human. Extract all of the proper nouns from the last line of conversation. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.\\n\\nThe conversation history is provided just in case of a coreference (e.g. \"What do you know about him\" where \"him\" is defined in a previous line) -- ignore items mentioned there that are not in the last line.\\n\\nReturn the output as a single comma-separated list, or NONE if there is nothing of note to return (e.g. the user is just issuing a greeting or having a simple conversation).\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how\\'s it going today?\\nAI: \"It\\'s going great! How about you?\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\\nLast line:\\nPerson #1: i\\'m trying to improve Langchain\\'s interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\\nOutput: Langchain\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how\\'s it going today?\\nAI: \"It\\'s going great! How about you?\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\\nLast line:\\nPerson #1: i\\'m trying to improve Langchain\\'s interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I\\'m working with Person #2.\\nOutput: Langchain, Person #2\\nEND OF EXAMPLE\\n\\nConversation history (for reference only):\\n{history}\\nLast line of conversation (for extraction):\\nHuman: {input}\\n\\nOutput:', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), summary_message_cls=<class 'langchain.schema.SystemMessage'>, memory_key='history')>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_kg.memory.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EntityMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 您好，张老三，感谢您下订单，我们会尽快处理您的订单。我们会尽快将您的订单发货，如果您有任何疑问，请随时联系我们，我们会尽快给您回复。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "\n",
    "entityMemory = ConversationEntityMemory(llm=llm)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory=entityMemory\n",
    ")\n",
    "\n",
    "answer=conversation.predict(input=\"我叫张老三，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是这个订单十几天了还没有收到货\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'张老三': '张老三是一位客户，订单号为2023ABCD，邮箱地址为customer@abc.com。', '2023ABCD': '2023ABCD is an order placed by Zhang Lao San with the email address customer@abc.com that has not yet been received after more than ten days.', 'customer@abc.com': 'Email address of Zhang Lao San, who placed an order with us with order number 2023ABCD.'}\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.entity_store.store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 您的订单号是2023ABCD。\n"
     ]
    }
   ],
   "source": [
    "answer=conversation.predict(input=\"我刚才的订单号是多少？\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 订单2023ABCD是您张老三的订单，您的邮箱地址是customer@abc.com。\n"
     ]
    }
   ],
   "source": [
    "answer=conversation.predict(input=\"订单2023ABCD是谁的订单？\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
